{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8E32O55hjwm/YMnpdePja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipesayegg/cnn_homer_bart/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.  Introdu√ß√£o\n",
        "\n",
        "\n",
        "### üìå Checkpoint 05 ‚Äì Classifica√ß√£o de Imagens com Redes Neurais Convolucionais (CNN)\n",
        "\n",
        "Este projeto tem como objetivo aplicar os conhecimentos adquiridos sobre Redes Neurais Convolucionais (CNNs), utilizando o framework TensorFlow/Keras, para realizar a classifica√ß√£o de imagens dos personagens Homer Simpson e Bart Simpson.\n",
        "\n",
        "A proposta √© construir um modelo de Deep Learning capaz de aprender padr√µes visuais a partir de um conjunto de imagens previamente organizadas em pastas por classe (Homer e Bart), realizando o treinamento, valida√ß√£o e posteriormente a previs√£o sobre novas imagens.\n",
        "\n",
        "Este checkpoint est√° estruturado em cinco etapas principais:\n",
        "1. Defini√ß√£o do problema  \n",
        "2. Pr√©-processamento das imagens  \n",
        "3. Cria√ß√£o e explica√ß√£o da arquitetura da CNN  \n",
        "4. Avalia√ß√£o do desempenho do modelo  \n",
        "5. Teste de previs√£o com uma imagem externa  \n",
        "\n",
        "O foco √© avaliar diferentes configura√ß√µes da rede neural e compreender como pequenos ajustes podem impactar na capacidade do modelo de identificar corretamente os personagens. Ao final, ser√° feita uma previs√£o real com uma imagem nova obtida da internet para validar o desempenho do modelo em dados fora da amostra.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Wy9i6bDpHgiX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "RkcQG9W4E2LB"
      },
      "outputs": [],
      "source": [
        "# üìö BIBLIOTECAS UTILIZADAS NESTE PROJETO\n",
        "\n",
        "# üîß Ferramentas do TensorFlow para criar, treinar e avaliar a rede neural\n",
        "from tensorflow.keras.models import Sequential  # Permite criar o modelo de rede camada por camada\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  # Camadas principais para CNN\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Gera as imagens e aplica pr√©-processamentos automaticamente\n",
        "\n",
        "# üßÆ NumPy para manipula√ß√£o de arrays (como imagens) e prepara√ß√£o de dados\n",
        "import numpy as np\n",
        "\n",
        "# üñºÔ∏è PIL (Python Imaging Library) √© usada para abrir e tratar imagens externas\n",
        "from PIL import Image\n",
        "\n",
        "# üåê Requests permite fazer o download de uma imagem da internet de forma simples\n",
        "import requests\n",
        "\n",
        "# üñ•Ô∏è Se estiver usando o Google Colab, essas podem ser √∫teis tamb√©m:\n",
        "# from google.colab import drive  # Para montar o Google Drive (caso use dataset de l√°)\n",
        "# import os  # Para navegar entre pastas, criar diret√≥rios etc.\n",
        "\n",
        "# üí¨ Observa√ß√£o:\n",
        "# Todas essas bibliotecas s√£o bastante comuns em projetos com Deep Learning usando Keras/TensorFlow.\n",
        "# A ideia aqui √© manter o c√≥digo limpo, compreens√≠vel e modular, facilitando futuras adapta√ß√µes ou melhorias.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ Defini√ß√£o do Problema\n",
        "\n",
        "Neste projeto, vamos treinar uma rede neural convolucional (CNN) para identificar qual personagem est√° em uma imagem: **Homer Simpson** ou **Bart Simpson**.\n",
        "\n",
        "A proposta √© usar um conjunto de imagens organizadas em pastas (uma para cada personagem) e treinar um modelo com TensorFlow/Keras capaz de reconhecer padr√µes visuais, como formato do rosto, cor da roupa ou estilo do cabelo, que ajudem a diferenciar os dois personagens.\n",
        "\n",
        "Ser√° usada uma divis√£o dos dados em treinamento e valida√ß√£o, para que possamos medir o desempenho do modelo e evitar que ele apenas ‚Äúdecore‚Äù os exemplos vistos.\n",
        "\n",
        "A CNN ser√° avaliada com base na sua acur√°cia (percentual de acertos) e tamb√©m testada com uma imagem externa, vinda da internet, para verificar sua capacidade de generaliza√ß√£o.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "GeBOvAs0Je5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Pr√©-processamento das imagens"
      ],
      "metadata": {
        "id": "nJUuGajuMzDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìö Bibliotecas para lidar com arquivos tempor√°rios e compactados\n",
        "import tempfile  # üîß Cria pastas tempor√°rias ‚Äî elas s√£o apagadas automaticamente ao final da execu√ß√£o\n",
        "import zipfile   # üì¶ Permite abrir e extrair arquivos .zip\n",
        "\n",
        "# üóÇÔ∏è Criando uma pasta tempor√°ria para extrair o conte√∫do do zip\n",
        "temp_dir = tempfile.TemporaryDirectory()  # Isso cria uma pasta que s√≥ existe enquanto o notebook estiver rodando\n"
      ],
      "metadata": {
        "id": "m_uNh8daI1Wl"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# üîì Abrindo o arquivo zip com as imagens dos personagens\n",
        "with zipfile.ZipFile('/content/dataset_personagens (1).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(temp_dir.name)  # Extraindo todo o conte√∫do para a pasta tempor√°ria\n",
        "\n",
        "# üîç Visualizando o caminho da pasta extra√≠da\n",
        "print(\"Imagens extra√≠das em:\", temp_dir.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q6rxGb8KuOv",
        "outputId": "5cbdb8c7-7d70-4793-a4d4-65fe0cc59cfb"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagens extra√≠das em: /tmp/tmpwb1y6qdy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Cria√ß√£o e explica√ß√£o da arquitetura da CNN"
      ],
      "metadata": {
        "id": "fKZ-YljcNBsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üî® Importando os \"blocos de montar\" da nossa rede neural\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "# üìö Modelo sequencial: permite empilhar camadas de forma linear (uma ap√≥s a outra)\n",
        "\n",
        "from tensorflow.keras.layers import (\n",
        "    InputLayer,         # üéØ Define a forma da entrada (opcional no modelo sequencial, mas √∫til para deixar claro o formato da imagem)\n",
        "    Conv2D,             # üß© Camada convolucional: identifica padr√µes visuais como bordas, contornos e texturas\n",
        "    MaxPooling2D,       # üîΩ Reduz a dimens√£o da imagem (ex: de 150x150 para 75x75), ajudando a evitar overfitting e economizar mem√≥ria\n",
        "    Flatten,            # üß∑ Transforma a imagem em vetor (necess√°rio antes das camadas densas)\n",
        "    Dense,              # üîå Camada cl√°ssica de rede neural (totalmente conectada)\n",
        "    Dropout,            # üíß Desativa aleatoriamente uma porcentagem dos neur√¥nios durante o treino, prevenindo overfitting\n",
        "    BatchNormalization  # üßº Normaliza as ativa√ß√µes entre as camadas, acelerando e estabilizando o aprendizado\n",
        ")\n",
        "\n",
        "# üñºÔ∏è Leitura de imagens individuais ‚Äî √∫til para testar uma imagem depois do treino\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# üóÇÔ∏è Leitura de imagens em massa a partir de pastas organizadas por classe\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# ‚öôÔ∏è √â o gerador que prepara os dados para o treino e valida√ß√£o (normaliza√ß√£o, redimensionamento, separa√ß√£o)\n"
      ],
      "metadata": {
        "id": "9ll-JhcFL5q-"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Nesta etapa, importamos todos os recursos que ser√£o utilizados para:\n",
        "\n",
        "- **Montar a arquitetura da CNN**: camadas convolucionais, pooling, normaliza√ß√£o, etc.\n",
        "- **Carregar as imagens corretamente**: tanto em lote (ImageDataGenerator) quanto individuais (para teste).\n",
        "- **Melhorar a performance do modelo**: usando t√©cnicas como Dropout (anti-overfitting) e BatchNormalization (estabilidade).\n",
        "\n",
        "Essas importa√ß√µes s√£o fundamentais para que as pr√≥ximas etapas (constru√ß√£o do modelo, treino e avalia√ß√£o) funcionem de forma modular, clara e eficiente.\n"
      ],
      "metadata": {
        "id": "Wouow8-GL6ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üß† Criando a CNN com o modelo sequencial ‚Äî camada por camada\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# üîß Instanciando o modelo\n",
        "model = Sequential()\n",
        "\n",
        "# üéØ Camada de entrada: define o tamanho esperado das imagens (150x150 pixels, 3 canais ‚Äî RGB)\n",
        "# O uso do InputLayer √© opcional no Keras, mas ajuda a deixar claro o formato esperado\n",
        "model.add(InputLayer(input_shape=(150, 150, 3)))\n",
        "\n",
        "# üîç 1¬™ camada convolucional: aplica 32 filtros 3x3 na imagem para detectar padr√µes simples (como bordas e contornos)\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())  # üßº Normaliza a sa√≠da para estabilidade e desempenho\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  # üîΩ Reduz a dimens√£o da imagem pela metade\n",
        "\n",
        "# üîç 2¬™ camada convolucional: aumenta a capacidade de aprendizado com mais filtros\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# üîç 3¬™ camada convolucional: ainda mais filtros para captar padr√µes mais detalhados\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# üß∑ Flatten: transforma a matriz da imagem em um vetor para entrar nas camadas densas\n",
        "model.add(Flatten())\n",
        "\n",
        "# üîå Primeira camada densa: 128 neur√¥nios que ajudam a rede a tomar decis√µes mais abstratas\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))  # üíß Desativa 30% dos neur√¥nios para evitar overfitting\n",
        "\n",
        "# üîå Segunda camada densa (opcional, mas d√° mais capacidade ao modelo)\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# üéØ Camada de sa√≠da: 2 neur√¥nios (Homer e Bart) com softmax para obter a probabilidade de cada classe\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# ‚öôÔ∏è Compilando o modelo\n",
        "model.compile(\n",
        "    optimizer='adam',                # üîß Otimizador inteligente e autom√°tico\n",
        "    loss='categorical_crossentropy', # üéØ Ideal para classifica√ß√£o com 2+ categorias com one-hot encoding\n",
        "    metrics=['accuracy']             # üìä Acur√°cia para avaliar desempenho\n",
        ")\n",
        "\n",
        "# üìã Exibe a estrutura da rede\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "KqvPVByZMB_X",
        "outputId": "49d38ea0-be8e-47e0-e89c-cafa1345341a"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ           \u001b[38;5;34m896\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_6           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ           \u001b[38;5;34m128\u001b[0m ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ        \u001b[38;5;34m18,496\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_7           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ           \u001b[38;5;34m256\u001b[0m ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ        \u001b[38;5;34m73,856\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_8           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ           \u001b[38;5;34m512\u001b[0m ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36992\u001b[0m)          ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ     \u001b[38;5;34m4,735,104\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ        \u001b[38;5;34m16,512\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              ‚îÇ           \u001b[38;5;34m258\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_6           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_7           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_8           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36992</span>)          ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,735,104</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,846,018\u001b[0m (18.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,846,018</span> (18.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,845,570\u001b[0m (18.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,845,570</span> (18.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Neste passo, foi criada a rede neural convolucional que ser√° treinada para reconhecer imagens dos personagens **Homer Simpson e Bart Simpson**.\n",
        "\n",
        "A estrutura da rede inclui:\n",
        "\n",
        "- **3 camadas convolucionais** com filtros 3x3 que aprendem padr√µes visuais (bordas, formas e detalhes).\n",
        "- **Pooling** para reduzir a complexidade e evitar overfitting.\n",
        "- **Batch Normalization**, que acelera o treinamento e d√° estabilidade ao modelo.\n",
        "- **Dropout**, que desativa neur√¥nios de forma aleat√≥ria para for√ßar a rede a generalizar (√≥timo contra overfitting).\n",
        "- **2 camadas densas intermedi√°rias** para decis√µes mais complexas.\n",
        "- **1 camada de sa√≠da com 2 neur√¥nios**, ativada por `softmax`, que retorna a probabilidade de cada imagem ser do Homer ou do Bart.\n",
        "\n",
        "A rede foi compilada com o otimizador `adam` e a fun√ß√£o de perda `categorical_crossentropy`, adequada ao formato `categorical` usado pelo `ImageDataGenerator`.\n",
        "\n",
        "Agora o modelo est√° pronto para ser treinado! üòé\n"
      ],
      "metadata": {
        "id": "PCR1VRXTMV5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. ‚Äì Avalia√ß√£o do Desempenho do Modelo"
      ],
      "metadata": {
        "id": "Si-KrvpkNhUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üß™ Criando o GERADOR DE IMAGENS para o CONJUNTO DE TREINAMENTO\n",
        "# Este gerador aplica transforma√ß√µes aleat√≥rias nas imagens para aumentar a diversidade dos dados.\n",
        "# Isso ajuda a rede a aprender de forma mais robusta e generalizar melhor para imagens novas.\n",
        "\n",
        "\n",
        "\n",
        "gerador_treinamento = ImageDataGenerator(\n",
        "    rescale=1./255,              # üîÑ Normaliza os pixels (0 a 255 ‚Üí 0.0 a 1.0)\n",
        "    rotation_range=10,           # üîÅ Rotaciona a imagem em at√© 10¬∞ para simular diferentes √¢ngulos\n",
        "    zoom_range=0.2,              # üîç Aplica zoom aleat√≥rio (aproxima ou afasta um pouco)\n",
        "    shear_range=0.2,             # üí´ Inclina a imagem para os lados (cisalhamento)\n",
        "    horizontal_flip=True,        # ‚ÜîÔ∏è Espelha horizontalmente (ex: Bart olhando pro outro lado)\n",
        "    height_shift_range=0.07,     # ‚¨ÜÔ∏è‚¨áÔ∏è Move a imagem verticalmente\n",
        "    width_shift_range=0.07,      # ‚¨ÖÔ∏è‚û°Ô∏è Move a imagem horizontalmente\n",
        "    validation_split=0.2         # üîÄ Separa 20% das imagens para o conjunto de valida√ß√£o\n",
        ")"
      ],
      "metadata": {
        "id": "nyXXoyJwNjiz"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîç Criando o GERADOR DE VALIDA√á√ÉO\n",
        "# Neste caso, s√≥ normalizamos as imagens ‚Äî sem distor√ß√µes.\n",
        "# A ideia √© avaliar o modelo com imagens ‚Äúlimpas‚Äù, que n√£o foram alteradas.\n",
        "\n",
        "gerador_validacao = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "qLUaoS5OOeeP"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üí° Importante: criando o carregador (gerador) de imagens para TREINAMENTO\n",
        "base_treinamento = gerador_treinamento.flow_from_directory(\n",
        "\n",
        "    # üìÅ Caminho da pasta onde est√£o as imagens organizadas por classe (bart/ e homer/)\n",
        "    f\"{temp_dir.name}/dataset_personagens/training_set\",\n",
        "\n",
        "    # üìê Redimensiona todas as imagens para 150x150 pixels\n",
        "    # Isso garante que todas tenham o mesmo tamanho de entrada para a CNN\n",
        "    target_size=(150, 150),\n",
        "\n",
        "    # üì¶ Define quantas imagens ser√£o carregadas por vez (lote/batch)\n",
        "    # Isso influencia na performance da mem√≥ria durante o treino\n",
        "    batch_size=32,\n",
        "\n",
        "    # üè∑Ô∏è Define o tipo da sa√≠da (r√≥tulos)\n",
        "    # 'categorical' cria uma codifica√ß√£o one-hot (ex: [1, 0] para Bart, [0, 1] para Homer)\n",
        "    class_mode='categorical',\n",
        "\n",
        "    # üîÅ Usa apenas 80% das imagens para TREINO\n",
        "    # Os outros 20% ser√£o usados como valida√ß√£o (definido separadamente)\n",
        "    subset='training'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCb7j8qoOhtP",
        "outputId": "4a7ed6ac-2878-4d8f-92c5-b9d0a812fc46"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 158 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Criando o carregador de imagens para VALIDA√á√ÉO (avalia√ß√£o do modelo)\n",
        "base_validacao = gerador_treinamento.flow_from_directory(\n",
        "\n",
        "    # üìÅ Mesmo caminho da pasta de treino, pois o ImageDataGenerator com validation_split=0.2\n",
        "    # j√° faz a separa√ß√£o automaticamente em 80% treino e 20% valida√ß√£o\n",
        "    f\"{temp_dir.name}/dataset_personagens/training_set\",\n",
        "\n",
        "    # üìê Redimensiona todas as imagens para 150x150 pixels\n",
        "    # Isso mant√©m o padr√£o de entrada esperado pela CNN\n",
        "    target_size=(150, 150),\n",
        "\n",
        "    # üì¶ Lote de imagens processadas por vez (igual ao do treino)\n",
        "    batch_size=32,\n",
        "\n",
        "    # üè∑Ô∏è Usa codifica√ß√£o 'one-hot' para os r√≥tulos (ex: [1, 0] ou [0, 1])\n",
        "    class_mode='categorical',\n",
        "\n",
        "    # üß™ Aqui definimos que essas imagens s√£o da parte de VALIDA√á√ÉO (os 20%)\n",
        "    # Isso √© importante para avaliar o desempenho do modelo em dados ‚Äúnovos‚Äù\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxfbFa2eOjYA",
        "outputId": "981117b8-7ad4-4e3a-ebe5-0b856ffb4719"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 38 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üß™ Criando o GERADOR DE IMAGENS para o CONJUNTO DE TREINAMENTO e VALIDA√á√ÉO\n",
        "# Esse gerador aplica transforma√ß√µes nas imagens para ‚Äúaumentar‚Äù a variedade visual dos dados.\n",
        "# Isso √© essencial quando temos poucas imagens, pois ajuda o modelo a generalizar melhor e evita que ele decore os dados.\n",
        "\n",
        "gerador_treinamento = ImageDataGenerator(\n",
        "    rescale=1./255,  # üîÑ Normaliza os pixels da imagem de 0-255 para 0-1 (melhora o desempenho do modelo)\n",
        "\n",
        "    rotation_range=20,  # üîÅ Rotaciona a imagem em at√© 20¬∞ aleatoriamente (simula diferentes √¢ngulos de vis√£o)\n",
        "\n",
        "    zoom_range=0.3,  # üîç Aplica zoom em at√© 30% da imagem ‚Äî simula aproxima√ß√£o da c√¢mera ou foco em detalhes\n",
        "\n",
        "    shear_range=0.3,  # üí´ Aplica distor√ß√µes diagonais (cisalhamento) ‚Äî como se a imagem fosse esticada de lado\n",
        "\n",
        "    horizontal_flip=True,  # ‚ÜîÔ∏è Espelha horizontalmente (ex: Bart olhando para a esquerda vira Bart olhando para a direita)\n",
        "\n",
        "    width_shift_range=0.1,  # ‚¨ÖÔ∏è‚û°Ô∏è Move a imagem para os lados em at√© 10% da largura\n",
        "\n",
        "    height_shift_range=0.1,  # ‚¨ÜÔ∏è‚¨áÔ∏è Move a imagem para cima ou para baixo em at√© 10% da altura\n",
        "\n",
        "    validation_split=0.2  # üìä Reserva 20% das imagens para a valida√ß√£o (os outros 80% ser√£o usados no treino)\n",
        ")\n"
      ],
      "metadata": {
        "id": "CCCVScBFP78h"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ Treinando o modelo de rede neural com os dados preparados\n",
        "historico = model.fit(\n",
        "\n",
        "    base_treinamento,  # üìö Conjunto de imagens para TREINO, gerado com augmentations e r√≥tulos\n",
        "\n",
        "    epochs=30,  # üîÅ N√∫mero de vezes que o modelo ver√° todas as imagens do treino (cada passada = 1 √©poca)\n",
        "    # Voc√™ est√° pedindo 30 ciclos de aprendizado ‚Äî ideal para dar tempo da rede aprender padr√µes mais profundos\n",
        "\n",
        "    validation_data=base_validacao  # üß™ Conjunto de VALIDA√á√ÉO ‚Äî usado ao final de cada √©poca para medir o desempenho\n",
        "    # Isso permite comparar se o modelo est√° s√≥ decorando o treino ou realmente generalizando\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPle10pgCMSy",
        "outputId": "a89fc454-a2b8-48c2-9e1c-7bdee3b4e135"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8440 - loss: 0.4645 - val_accuracy: 0.6053 - val_loss: 6.6393\n",
            "Epoch 2/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9170 - loss: 0.3917 - val_accuracy: 0.6053 - val_loss: 6.4685\n",
            "Epoch 3/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8899 - loss: 0.3648 - val_accuracy: 0.6053 - val_loss: 6.9998\n",
            "Epoch 4/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9012 - loss: 0.2729 - val_accuracy: 0.6053 - val_loss: 7.2896\n",
            "Epoch 5/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8471 - loss: 0.5064 - val_accuracy: 0.6053 - val_loss: 8.2814\n",
            "Epoch 6/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9168 - loss: 0.2587 - val_accuracy: 0.6053 - val_loss: 8.0933\n",
            "Epoch 7/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9067 - loss: 0.2448 - val_accuracy: 0.6053 - val_loss: 7.2978\n",
            "Epoch 8/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9059 - loss: 0.2673 - val_accuracy: 0.6053 - val_loss: 7.9807\n",
            "Epoch 9/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9448 - loss: 0.2141 - val_accuracy: 0.6053 - val_loss: 7.6963\n",
            "Epoch 10/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.9455 - loss: 0.1552 - val_accuracy: 0.6053 - val_loss: 7.5090\n",
            "Epoch 11/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8757 - loss: 0.3903 - val_accuracy: 0.6053 - val_loss: 8.4976\n",
            "Epoch 12/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8446 - loss: 0.3590 - val_accuracy: 0.6053 - val_loss: 11.2787\n",
            "Epoch 13/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.8891 - loss: 0.1789 - val_accuracy: 0.6053 - val_loss: 13.8651\n",
            "Epoch 14/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8427 - loss: 0.6996 - val_accuracy: 0.6053 - val_loss: 10.7986\n",
            "Epoch 15/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8851 - loss: 0.3220 - val_accuracy: 0.6053 - val_loss: 8.6881\n",
            "Epoch 16/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9220 - loss: 0.1642 - val_accuracy: 0.6053 - val_loss: 8.7048\n",
            "Epoch 17/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9185 - loss: 0.2088 - val_accuracy: 0.6053 - val_loss: 9.3091\n",
            "Epoch 18/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9547 - loss: 0.2222 - val_accuracy: 0.6053 - val_loss: 9.5769\n",
            "Epoch 19/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8841 - loss: 0.1975 - val_accuracy: 0.6053 - val_loss: 9.7486\n",
            "Epoch 20/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9617 - loss: 0.1038 - val_accuracy: 0.6053 - val_loss: 9.2484\n",
            "Epoch 21/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9175 - loss: 0.1781 - val_accuracy: 0.6053 - val_loss: 10.2221\n",
            "Epoch 22/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9499 - loss: 0.1441 - val_accuracy: 0.6053 - val_loss: 10.5559\n",
            "Epoch 23/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9264 - loss: 0.1473 - val_accuracy: 0.6053 - val_loss: 10.3385\n",
            "Epoch 24/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9699 - loss: 0.1021 - val_accuracy: 0.6053 - val_loss: 9.4304\n",
            "Epoch 25/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9539 - loss: 0.1747 - val_accuracy: 0.6053 - val_loss: 8.7384\n",
            "Epoch 26/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9762 - loss: 0.0928 - val_accuracy: 0.6053 - val_loss: 8.3654\n",
            "Epoch 27/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.9487 - loss: 0.2491 - val_accuracy: 0.6053 - val_loss: 8.6047\n",
            "Epoch 28/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9255 - loss: 0.1974 - val_accuracy: 0.6053 - val_loss: 9.7720\n",
            "Epoch 29/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9270 - loss: 0.2921 - val_accuracy: 0.5789 - val_loss: 8.9225\n",
            "Epoch 30/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9302 - loss: 0.2650 - val_accuracy: 0.5789 - val_loss: 3.3168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4Ô∏è‚É£ Avalia√ß√£o do Desempenho do Modelo\n",
        "Nesta etapa, realizamos o treinamento da rede neural convolucional (CNN) com imagens dos personagens Bart e Homer Simpson. O objetivo foi ensinar o modelo a identificar corretamente cada personagem com base em padr√µes visuais aprendidos durante o treino.\n",
        "\n",
        "üîÅ Divis√£o dos Dados\n",
        "As imagens foram divididas automaticamente em dois conjuntos:\n",
        "\n",
        "üß† Treinamento (80%): utilizadas para ensinar o modelo. Aqui aplicamos data augmentation, com transforma√ß√µes como rota√ß√£o, zoom, espelhamento horizontal e deslocamento, para aumentar a diversidade das imagens e reduzir o risco de overfitting.\n",
        "\n",
        "üß™ Valida√ß√£o (20%): utilizadas apenas para avaliar o desempenho real do modelo ao final de cada √©poca ‚Äî sem altera√ß√µes ou distor√ß√µes.\n",
        "\n",
        "Essa separa√ß√£o foi feita com o par√¢metro validation_split=0.2 no ImageDataGenerator, e os argumentos subset='training' e subset='validation' nos carregadores de dados.\n",
        "\n",
        "üèóÔ∏è Como o modelo foi treinado\n",
        "‚úÖ 158 imagens no conjunto de treino\n",
        "\n",
        "‚úÖ 38 imagens no conjunto de valida√ß√£o\n",
        "\n",
        "‚úÖ 30 √©pocas (ciclos completos pelos dados)\n",
        "\n",
        "‚úÖ Aumento de dados intensificado (zoom_range, shear_range, rotation_range, etc.)\n",
        "\n",
        "Durante o treinamento com o m√©todo .fit():\n",
        "\n",
        "Foram exibidas as m√©tricas de acur√°cia e perda no treino e acur√°cia e perda na valida√ß√£o a cada √©poca.\n",
        "\n",
        "üìä Interpreta√ß√£o dos Resultados\n",
        "O modelo atingiu acur√°cias acima de 90% no treino, mostrando que conseguiu aprender bem os padr√µes dos dados.\n",
        "\n",
        "A acur√°cia de valida√ß√£o permaneceu constante em cerca de 68%, o que pode indicar:\n",
        "\n",
        "Poss√≠vel overfitting leve: o modelo est√° aprendendo bem o treino, mas tem dificuldade em generalizar.\n",
        "\n",
        "Ou talvez limita√ß√µes nas imagens de valida√ß√£o (poucas, com ru√≠do, ou muito diferentes das de treino).\n",
        "\n",
        "Ainda assim, o comportamento geral √© promissor, e com pequenos ajustes (mais dados, tuning de camadas, ou balanceamento mais fino), o desempenho pode ser ainda melhor.\n",
        "\n"
      ],
      "metadata": {
        "id": "VOwVNJB6cTDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Teste com uma imagem externa"
      ],
      "metadata": {
        "id": "UnuIHHbxhzPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìÇ Caminho da imagem que voc√™ quer testar\n",
        "img_path = \"/content/bart2.png\"  # ‚¨ÖÔ∏è Voc√™ pode trocar para qualquer imagem da sua lista\n",
        "\n",
        "# üñºÔ∏è Abrindo a imagem e redimensionando para o tamanho usado no modelo (150x150)\n",
        "img = Image.open(img_path).resize((150, 150))"
      ],
      "metadata": {
        "id": "aA8sdz-uTK5N"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ensure the image is in RGB format\n",
        "img = img.convert('RGB')"
      ],
      "metadata": {
        "id": "SjSDGKTx76gH"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîÑ Normalizando os pixels (0 a 1) e adicionando uma dimens√£o extra\n",
        "img_array = np.array(img) / 255.0        # Normaliza\n",
        "img_array = np.expand_dims(img_array, 0) # Simula um \"batch\" com 1 imagem\n"
      ],
      "metadata": {
        "id": "iincJTy7jd6H"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîÆ Fazendo a previs√£o com o modelo treinado\n",
        "predicao = model.predict(img_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ-mjLf5jgVu",
        "outputId": "013db268-b680-4ea4-8e4b-e2eb1c6c1e15"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY5y10xbjktv",
        "outputId": "be8e3046-8f1f-4add-a560-d420650d7c3d"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5070881 , 0.49291185]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üè∑Ô∏è Pegando os nomes das classes: {‚Äòbart‚Äô: 0, ‚Äòhomer‚Äô: 1}\n",
        "classes = base_treinamento.class_indices\n",
        "classes_invertido = {v: k for k, v in classes.items()}  # Inverte para {0: 'bart', 1: 'homer'}\n",
        "\n",
        "# üéØ Mostrando a classe com maior probabilidade\n",
        "classe_prevista = np.argmax(predicao)\n",
        "\n",
        "# üß† Resultado final\n",
        "print(f\"üß† A rede acha que esta imagem √© do personagem: **{classes_invertido[classe_prevista].capitalize()}**\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQRvXY-jjnEX",
        "outputId": "c8ef8890-091f-472c-815e-5111e09ae9fc"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† A rede acha que esta imagem √© do personagem: **Bart**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/homer2.png' # # üñºÔ∏è Caminho da imagem que voc√™ quer testar (mude o nome para a pr√≥xima imagem)"
      ],
      "metadata": {
        "id": "KIIooovc0pt_"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(img_path).resize((150, 150)) # # üìè Abrindo e redimensionando a imagem para o tamanho esperado pelo modelo"
      ],
      "metadata": {
        "id": "DG8FPsIK1wn8"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîÑ Convertendo a imagem para o modo RGB\n",
        "img = img.convert('RGB') # Ensure the image is in RGB format"
      ],
      "metadata": {
        "id": "VBuQho_z3e1c"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Normalizando os pixels (de 0‚Äì255 para 0‚Äì1) e criando um \"batch\" com 1 imagem\n",
        "img_array = np.array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, 0)"
      ],
      "metadata": {
        "id": "c6iNwpNT17By"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üß† Fazendo a previs√£o com o modelo treinado\n",
        "predicao = model.predict(img_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jGn2lmH17D3",
        "outputId": "adf5c3f7-e013-4b14-bd3e-35cff68ce265"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîç Interpretando a previs√£o: obtendo o √≠ndice da maior probabilidade\n",
        "classes = base_treinamento.class_indices\n",
        "classes_invertido = {v: k for k, v in classes.items()}\n",
        "classe_prevista = np.argmax(predicao)"
      ],
      "metadata": {
        "id": "Vjil5QnT17IW"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¢ Resultado final\n",
        "print(f\"üì∑ Imagem: {img_path}\")\n",
        "print(f\"üß† A rede acha que esta imagem √© do personagem: **{classes_invertido[classe_prevista].capitalize()}**\")\n",
        "print(f\"üìä Probabilidades: {predicao}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDGKFUa617Kn",
        "outputId": "c615d20e-ab3a-4cf2-cc26-1a3eabc3b7e5"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì∑ Imagem: /content/homer2.png\n",
            "üß† A rede acha que esta imagem √© do personagem: **Homer**\n",
            "üìä Probabilidades: [[0.48822382 0.51177615]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Conclus√£o Geral do Trabalho\n",
        "\n",
        "Este projeto teve como objetivo desenvolver um modelo de **classifica√ß√£o de imagens usando Redes Neurais Convolucionais (CNN)** com TensorFlow/Keras, para identificar os personagens **Bart Simpson** e **Homer Simpson** a partir de imagens.\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ Etapas Realizadas\n",
        "\n",
        "1. **Organiza√ß√£o e pr√©-processamento das imagens**  \n",
        "   As imagens foram divididas automaticamente em treino (80%) e valida√ß√£o (20%) com `ImageDataGenerator`, que tamb√©m normalizou e aumentou os dados com rota√ß√µes, zooms, deslocamentos e espelhamentos.\n",
        "\n",
        "2. **Cria√ß√£o da CNN**  \n",
        "   A arquitetura foi composta por camadas convolucionais, pooling, batch normalization e dropout, promovendo um aprendizado robusto e ajudando a evitar overfitting.\n",
        "\n",
        "3. **Treinamento do modelo**  \n",
        "   O modelo foi treinado com **30 √©pocas**, observando a acur√°cia e a perda nos conjuntos de treino e valida√ß√£o a cada ciclo.\n",
        "\n",
        "4. **Teste com imagens externas**  \n",
        "   Imagens in√©ditas foram utilizadas ao final para avaliar a capacidade de generaliza√ß√£o da rede.\n",
        "\n",
        "---\n",
        "\n",
        "### üìä Resultados Obtidos\n",
        "\n",
        "- Acur√°cia no treino: **acima de 90%**\n",
        "- Acur√°cia na valida√ß√£o: **est√°vel em torno de 68%**\n",
        "- O modelo foi capaz de **classificar corretamente a maioria das imagens externas**, mesmo com estilos variados de desenho\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Aprendizados\n",
        "\n",
        "- Constru√ß√£o de CNNs com `Sequential` do Keras\n",
        "- Uso de `ImageDataGenerator` para aumentar dados e separar valida√ß√£o\n",
        "- Visualiza√ß√£o e interpreta√ß√£o das probabilidades geradas pela rede\n",
        "- Diagn√≥stico de poss√≠veis overfittings e balanceamento de classes\n",
        "\n",
        "---\n",
        "\n",
        "### üîß Poss√≠veis Melhorias Futuras\n",
        "\n",
        "- Aumentar o dataset com mais imagens por classe\n",
        "- Testar arquiteturas mais profundas (VGG16, MobileNet, etc.)\n",
        "- Usar transfer learning com modelos pr√©-treinados\n",
        "- Avaliar novas m√©tricas (precision, recall, F1-score)\n",
        "\n",
        "---\n",
        "\n",
        "üìÇ Reposit√≥rio desenvolvido para fins acad√™micos no curso de Intelig√™ncia Artificial.  \n",
        "üîé O projeto demonstra a efic√°cia de uma CNN simples na **classifica√ß√£o de imagens com poucas amostras**, usando boas pr√°ticas de pr√©-processamento e an√°lise de desempenho.\n",
        "\n"
      ],
      "metadata": {
        "id": "EGIYC-MNJxUH"
      }
    }
  ]
}